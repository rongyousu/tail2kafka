* 简介
tail2kafka 是一个小工具，用于把文件内容实时 *逐行* 发送到 [[https://kafka.apache.org/][kafka]], 类似于linux ~tail~ 命令实时把文件输出到屏幕上。在把文件行发送到kafka前，可以对文件行做一些 ~编程工作~ ，这里用到了 [[https://www.lua.org/][lua]]。

编译后的tail2kafka只有一个可执行文件，没有任何依赖，使用起来非常简单

* 编译安装启动
** 准备依赖
~make get-deps~ 下载依赖库。在编译完成后，依赖库被静态链接到tail2kafka，所以tail2kafka仅有一个可执行文件，仅复制这一个文件到目标机器，就完成部署。

** 编译安装
编译 ~make~ 安装 ~make install~ ，默认路径是 ~/usr/local/bin~ 。如果需要更改安装路径 ~make install INSTALLDIR=/installpath~

也可以使用 =./scripts/makerpm= 打rpm包

** 启动
启动 ~tail2kafka /etc/tail2kafka~ 读取 =/etc/tail2kafka= 目录下的lua文件，并启动。

停止 ~kill $(cat /var/run/tail2kafka.pid)~

重新加载配置 ~kill -HUP $(cat /var/run/tail2kafka.pid)~

** 架构
=tail2kafka= 启动后，有两个进程，子进程完成实际工作，父进程负责重新加载配置和子进程存活检测。

* 数据分区和完整性
=tail2kafka= 支持三种分区方式，固定分区、根据机器IP分区和随机分区。

固定分区是指定一个固定分区，根据机器IP分区是对IP做hash自动计算出分区，两者的共同点是文件的数据总是发送到同一个分区，这两种方式可以保证绝对不丢数据。因为文件本身就是一个队列，kafka的一个分区也是一个队列， =队列= 之间复制保证数据完整性。缺点是分区不均衡，且分区数量受机器数量限制，为了克服这个限制可以在消费时做二次分区。

随机分区是随机选择一个分区发送数据，一个文件的数据发送到多个分区，相当于一个 =队列= 的数据复制到多个 =队列= ，没办法维护队列之间的映射关系，也就没法记录已发送数据在文件里的offset，进程重启时没法保证数据不丢失。好处是分区均衡。

* 配置
参考 [[./doc/tail2kafka-config.org][tail2kafka 配置]]

* 内置集群部署支持
参考 [[./doc/tail2kafka-cluster.org][tail2kafka 集群]]

* 性能
虚拟机测试供参考，测试脚本在 ~blackboxtest/loadtest.sh~

| 数据大小 | 平均每行大小 | ACK | 行/ 秒 | 字节/ 秒 |
|----------+--------------+-----+--------+----------|
| 4G       |         2048 |   1 |  15267 | 31M      |
| 4G       |         2048 |   0 |  25641 | 52M      |
| 2G       |         1024 |   1 |  30769 | 32M      |
| 2G       |         1024 |   0 |  40816 | 42M      |
| 1G       |          512 |   1 |  58823 | 31M      |
| 1G       |          512 |   0 |  90909 | 48M      |
| 512M     |          256 |   1 | 117647 | 32M      |
| 512M     |          256 |   0 | 117647 | 32M      |

* 限制
- 需要文件使用 =\n= 作为换行符
- 一行最长2M，不建议使用很长的行，可能触发librdkafka的BUG
